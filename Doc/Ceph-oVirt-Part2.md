![](https://ovirt.org/images/wiki/Cinder_flow_illustration.png?1478101463)

# Настройка SDS Ceph в распределенной системе oVirt 4.1/4.2 #

## (Часть №2. Cinder + Ceph RBD)

### Важно!: Данная методика и контейнер находятся на стадии тестирования. 

Всем доброго времени суток. В предыдущей статье мы развернули систему виртуализации oVirt с использованием отказоустойчивой программной дисковой подсистемы Ceph. На данный момент мы имеем кластер oVirt, который работает с файловым хранилищем CephFS через абстракцию, предоставляющую ресурсы CephFS, как понятный для oVirt NFS(V4) том.

Казалось - бы, зачем делать что - либо еще ? Ведь все работает нормально, отказоустойчивого, надежно.  Но главным недостатком данной схемы - это скорость, так называемый IOPS (количество операций ввода/вывода в секунду). Она конечно намного выше, чем при работе с GlusterFS, но если можно получить больше IOPS, значит их нужно получить.

И так, приступим.

***Что нужно знать, перед началом дальнейших каких - либо действий ?***

Ceph RBD не является, так скажем "родной" системой хранения для oVirt. Напрямую oVirt не может создавать/удалять, работать с томами Ceph RBD. Но разработчиками oVirt реализована возможность использования данной схемы через External Providers (Внешние провайдеры).

### Теперь более подробно, что и как работает.

Внешним провайдером для связки oVirt с Ceph RBD выступает один из компонентов фреймворка OpenStack, собственно служба Cinder, которая предоставляет в OpenStack доступ к дисковым подсистемам. Вот ее мы и будем использовать.

**Как происходит взаимодействие oVirt c Cinder ?**
 
При создании тома в системе oVirt для виртуальной машины, или еще для каких либо целей, система oVirt дает команду Cinder, который в свою очередь дает команду Ceph создать том RBD. Во время создания тома oVirt выставляет блокировку и ждет завершения операции. По окончанию операции oVirt получает от Cinder сообщение о завершении создания тома. На этом процедура заканчивается.

**Что происходит при запуске виртуальной машины при использовании тома Ceph RBD ?**

Перед запуском oVirt дает команду Cinder о блокировке тома RBD в Ceph, после этого следует запуск самой виртуальной машины, которая уже без абстракций и посредников подключает том RBD напрямую. Вся дальнейшая работа с томом происходит следующим образом QUEMU <--> Ceph RBD. 

По причине того, что мы не используем абстракций и прослоек в данной схеме, мы получаем более высокие IOPS, да и сам Ceph RBD является более производительным чем Ceph FS.

**Какие есть ограничения ?**

Есть ли ограничения в использовании oVirt + Ceph RBD ? Они есть! В oVirt для внешних провайдеров не работает механизм перемещения томов из домена в домен, это становится возможным только с использованием дополнительного ПО на уровне виртуальной машины, например Acronis или разработкой собственных инструментов, которые будут выполнять эти операции через API Ovirt и Ceph.

### С теорией поверхностно разобрались, теперь приступаем к реализации.

**1.Для начала подготовим пул в Ceph, для работы с RBD томами.**   

	# Создаем пул
 
	ceph osd pool create volumes 128						# Очень внимательно расчитываем PG
	ceph osd pool application enable volumes rbd

	# Создаем пользователя и выгружаем его ключь, в дальнейшем он нам будет нужен

	ceph auth get-or-create client.cinder mon 'profile rbd' osd 'profile rbd pool=volumes'
	ceph auth get-or-create client.cinder  | tee /etc/ceph/ceph.client.cinder.keyring
	ceph auth get-key client.cinder | tee /etc/ceph/client.cinder.key

**2.Готовим хосты oVirt для работы с Ceph**

Если у Вас oVirt развернут на тех - же хостах, что и Ceph, данный пункт можно пропустить.

	# Воспользуемся ceph-deploy для установки компонентов Ceph на oVirt хосты.
	# Указываем свои хосты <Server1> <Server2> <Server3>

	cd /opt/ceph-admin
	ceph-deploy install --release luminous <Server1> <Server2> <Server3>

Копируем ключи для пользователя cinder, которого создали выше, для доступа к RBD

	# Указываем свои хосты <Server1> <Server2> <Server3>

	for i in <Server1> <Server2> <Server3>;do scp /etc/ceph/*cinder* root@$i:/etc/ceph/; done

**3.Развертывание Docker контейнера Cinder в системе oVirt**

В данной статье, мы рассмотрим только лишь развертывание и настройку самого контейнера, работа Cinder + keystone, которые находятся внутри данного контейнера, их механизмы и работа, это тема для отдельной статьи.

Вариантов развертывания может быть два: развертывание внутри виртуальной машины HostedEngine и развертывание на отдельной виртуальной машине внутри oVirt.


***Развертывание контейнера внутри HostedEngine(рекомендовано)***

Данный метод является рекомендованным, так как после запуска HostedEngine, начинаются процессы по анализу хостов, томов и т.д. кластера oVirt и после того, как все элементы кластера oVirt выходят в рабочее состояние, начинается автоматический запуск виртуальных машин, которые имеют статус HA(высокой доступности). Если контейнер с Cinder размещен внутри HostedEngine, он стартует вместе с ним и в момент автоматического запуска виртуальных машин он уже в работоспособном состоянии, соответственно RBD тома уже доступны.

Данный способ является приемлемым, так как работающие сервисы и процессы внутри HostedEngine не затрагиваются.

Перед началом развертывания контейнера внутри HostedEngine, нужно увеличить выделенную оперативную память для этой виртуальной машины на 4Гб. 

Развертывание контейнера производим внутри виртуальной машины HostedEngine:

	# Устанавливаем репозитарий epel
	
	yum -y install epel-release
	yum -y install docker
	
	# Запускаем Docker и включаем его автостарт при запуске.

	systemctl enable docker
	systemctl start docker

	# Развертывание самого контейнера с Cinder
	# <HOSTNAME> - указываем имя хоста HostedEngine (должно ресолвиться в DNS)
	#	
	# Администраторский и пользовательские пароли службы Cinder  
	# <ADMIN_PASS>  - Пароль администратора Cinder (По умолчанию: ADMIN_PASS
	# <CINDER_PASS> - Пароль cinder пользователя Cinder (По умолчанию: CINDER_PASS)

	docker run --restart=always -d --name docker-cinder-12 
	-h <HOSTNAME>											 
	-e ADMIN_PASS=<ADMIN_PASS>			# Можно не указывать (удалить строку)
	-e CINDER_PASS=<CINDER_PASS>		# Можно не указывать (удалить строку) 
	-e RBD_USER=cinder 
	-e RBD_POOL=volumes 
	-e CEPH_CLUSTER=ceph 
	-v /opt/docker/cinder/etc/cinder:/etc/cinder 
	-v /etc/ceph:/etc/ceph 
	-v /opt/docker/cinder/etc/keystone:/etc/keystone 
	-v /opt/docker/cinder/lib/cinder:/var/lib/cinder 
	-v /opt/docker/cinder/lib/mysql:/var/lib/mysql 
	-v /opt/docker/cinder/lib/keystone:/var/lib/keystone 
	-v /opt/docker/cinder/log:/var/log 
	-p 35357:35357 -p 8776:8776 -p 5000:5000 
	lantaris/docker-cinder-12


Дожидаемся старта контейнера. Первый запуск может занять 5-10 минут, т.к. создаются базы и настраиваются службы Cinder и Keystone. 

Мониторим запуск контейнера(выполняется внутри HostedEngine:

	tail -f /opt/docker/cinder/log/supervisor/prepare.out.log

Дожидаемся вывода сообщения о завершении подготовки и продолжаем настройку oVirt.


**4.Настройка External Providers в системе oVirt**

1. В разделе "External Providers" добавляем нового провайдера.
2. Name - указываем любое удобное имя.
3. Type - OpenStack Volume
4. Provider URL - http://<имя хоста с контейнером>:8776
5. Requires Authentication - устанавливаем флаг.
6. Username - cinder
7. Password - указываем раннее заданный для контейнера пароль в параметре <CINDER_PASS>
8. Tenant Name - service
9. Authentication URL - http://<имя хоста с контейнером>:35357/v2.0/


После заполнения всех параметров, нажимаем на кнопку "Test", если все сделано правильно, то тесть должен пройти успешно. Далее нажимаем Ok, сохраняем провайдера.

Переходим в закладку "Authentication Keys", добавляем новую запись

1. UUID - можно указать свой UUID при запуске контейнера в переменной (RBD_SECRET_UUID),
		  если не указано, контейнер генерирует UUID сам. Посмотреть его маожно следующим образом на виртуальной машине HostedEngine
		  ( docker exec docker-cinder-12 cat /etc/cinder/cinder.conf |grep rbd_secret_uuid )
2. Value - ключь пользователя cinder, созданного в Ceph. (cat /etc/ceph/client.cinder.key)

Сохраняем настройки. Система oVirt готова для использования томов Ceph RBD. 

При создании тома для виртуальной машины, переходим в закладку Cinder и далее создаем диск как обычно.


***Развертывание контейнера на отдельной виртуальной машине***

Развертывание на отдельной виртуальной машине ни чем не отличается от развертывания внутри HostedEngine. Единственно что нужно знать, это то, что отдельная виртуальная машина с Cinder контейнером должна быть настроена таким образом, что - бы она стартовала раньше, чем будут попытки oVirt системы запустить HA виртуальные машины. Данный задачу можно реализовать через механизм Affinity системы oVirt.

## Заключение:

Данный способ с использованием контейнера Cinder только проходит тестирование. Если вы нашли какие либо ошибки или недочеты, прошу присылать на EMAIL: edik.ponomarenko@mail.ru


## Использованные в статье материалы:

[Официальный сайт Openstack](https://www.openstack.org/)

[Официальный сайт oVirt](https://ovirt.org/)

## Благодарности:

Алексей Костин (Telegram: @rumanzo): помощь в нюансах связки Cinder + oVirt

Мельников Владимир (Telegram: @ranebull): за оформление статей и документов

Каналу KVM (PVE/oVirt etc) (Telegram: https://t.me/pro_kvm): за советы и мудрость


**Всем удачной работы и новых познаний в сфере ИТ.**
